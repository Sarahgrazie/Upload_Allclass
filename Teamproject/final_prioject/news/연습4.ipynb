{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-03-07 2024-01-20\n",
      "다운 받고 있습니다------\n",
      "더 이상 뉴스가 없습니다.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from datetime import datetime, timedelta\n",
    "from dateutil import parser\n",
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "# 다른 경로로 csv 파일 저장\n",
    "PATH = 'C:\\\\Education\\\\teamproject\\\\final_prioject\\\\news'\n",
    "\n",
    "\n",
    "def crawler(company_code, start_date, end_date):\n",
    "    page = 1\n",
    "    \n",
    "    while True:\n",
    "        url = 'https://finance.naver.com/item/news_news.nhn?code=' + str(company_code) + '&page=' + str(page)\n",
    "        source_code = requests.get(url).text\n",
    "        html = BeautifulSoup(source_code, \"lxml\")\n",
    "        \n",
    "        titles = html.select('.title')\n",
    "        title_result = [title.get_text(strip=True) for title in titles]\n",
    "        \n",
    "        links = html.select('.title')\n",
    "        link_result = ['https://finance.naver.com' + link.find('a')['href'] for link in links]\n",
    "        \n",
    "        dates = html.select('.date')\n",
    "        date_result = [date.get_text(strip=True) for date in dates]\n",
    "        \n",
    "        # 문자열 형식의 날짜를 datetime으로 변환\n",
    "        converted_dates = []\n",
    "        for date_str in date_result:\n",
    "            try:\n",
    "                # dateutil.parser.parse를 사용하여 날짜를 자동으로 파싱\n",
    "                converted_date = parser.parse(date_str).date()\n",
    "                converted_dates.append(converted_date)\n",
    "            except ValueError:\n",
    "                print(f\"Ignoring invalid date: {date_str}\")\n",
    "        \n",
    "        # 시작 날짜부터 1년 6개월 전의 뉴스만 가져오도록 필터링\n",
    "        result = {\"날짜\": converted_dates, \"기사제목\": title_result, \"링크\": link_result}\n",
    "        df_result = pd.DataFrame(result)\n",
    "        df_result = df_result[(df_result['날짜'] >= start_date) & (df_result['날짜'] <= end_date)]\n",
    "        \n",
    "        if not df_result.empty:\n",
    "            print(\"다운 받고 있습니다------\")\n",
    "            df_result.to_csv(f'{PATH}\\\\page{page}.csv', mode='w', encoding='utf-8-sig', index=False)\n",
    "            page += 1\n",
    "        else:\n",
    "            print(\"더 이상 뉴스가 없습니다.\")\n",
    "            break\n",
    "\n",
    "def convert_to_code(company, start_date, end_date):\n",
    "    # 가정한 데이터프레임 생성\n",
    "    data1 = pd.read_csv(f'{PATH}\\\\stocklistcode.csv')\n",
    "    \n",
    "    company_name_column = data1['종목명']\n",
    "    company_code_column = data1['종목코드']\n",
    "    \n",
    "    keys = company_name_column.tolist()\n",
    "    values = company_code_column.tolist()\n",
    "    \n",
    "    dict_result = dict(zip(keys, values))\n",
    "    \n",
    "    pattern = '[a-zA-Z가-힣]+' \n",
    "    \n",
    "    if bool(re.match(pattern, company)) == True:\n",
    "        company_code = dict_result.get(str(company))\n",
    "        crawler(company_code, start_date, end_date)\n",
    "    else:\n",
    "        company_code = str(company)\n",
    "        crawler(company_code, start_date, end_date)\n",
    "\n",
    "def main():\n",
    "    info_main = input(\"=\"*50+\"\\n\"+\"실시간 뉴스기사 다운받기.\"+\"\\n\"+\" 시작하시려면 Enter를 눌러주세요.\"+\"\\n\"+\"=\"*50)\n",
    "    \n",
    "    company = input(\"종목명이나 코드 입력: \") \n",
    "    end_date = input(\"종료 날짜(YYYY.MM.DD 또는 YYYYMMDD) 입력: \")\n",
    "    \n",
    "    try:\n",
    "        end_date = datetime.strptime(end_date.replace('.', ''), '%Y%m%d').date()\n",
    "    except ValueError:\n",
    "        print(\"잘못된 날짜 형식입니다. 'YYYY.MM.DD' 또는 'YYYYMMDD' 형식으로 다시 입력해주세요.\")\n",
    "        return\n",
    "    \n",
    "    # 현재 날짜로부터 1년 6개월 전의 날짜 계산\n",
    "    start_date = datetime.now() - timedelta(days=int(1.8*365/2))\n",
    "    \n",
    "    # 디렉토리가 없으면 생성\n",
    "    if not os.path.exists(PATH):\n",
    "        os.makedirs(PATH)\n",
    "\n",
    "    print(start_date.date(), end_date)\n",
    "    convert_to_code(company, start_date.date(), end_date)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml-dev",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
